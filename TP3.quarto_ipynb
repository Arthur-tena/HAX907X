{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"TP3 SVM\"\n",
        "author: \"Arthur TENA\"\n",
        "format: pdf\n",
        "toc: true            \n",
        "toc-depth: 3\n",
        "pdf-engine: xelatex\n",
        "output: pdf_document\n",
        "---"
      ],
      "id": "6a8d7d84"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| include: false\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from svm_source import *\n",
        "from sklearn import svm\n",
        "from sklearn import datasets\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.decomposition import PCA\n",
        "from time import time\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.style.use('ggplot')"
      ],
      "id": "3022f619",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Support Vector Machines\n",
        "Le \\underline{Support Vector Machine} (SVM) est une méthode d'apprentissage supervisé principalement utilisée pour les tâches de classification et, dans certains cas, de régression. \n",
        "\n",
        "L'idée principale du SVM est de trouver une frontière ou un hyperplan qui sépare au mieux les différentes classes de données dans un espace à plusieurs dimensions. Pour un problème de classification binaire (deux classes), le SVM cherche à maximiser la marge entre les points les plus proches des deux classes et l'hyperplan séparateur.\n",
        "\n",
        "Les vecteurs de support sont les points de données qui se trouvent le plus près de l'hyperplan. Ces points déterminent la position et l’orientation de l'hyperplan, car ce sont eux qui contraignent la marge. La marge est définie comme la distance entre ces points critiques et l'hyperplan.\n",
        "\n",
        "!(SVM.png){width=500}\n",
        "\n",
        "Nous allons dans un premier temps regarder quelques applications simple de la méthode SVM avec le data set \\textit{iris}, puis nous verrons un exemple de classification de visages \n",
        "\n",
        "# Partie 1 : exemples d'applications\n",
        "\n",
        "### Question 1 \n"
      ],
      "id": "5a67f8d3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| include: false\n",
        "\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X = X[y != 0, :2]\n",
        "y = y[y != 0]\n",
        "X, y = shuffle(X, y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "parameters = {'kernel': ['linear'], 'C': list(np.logspace(-3, 3, 200))}\n",
        "\n",
        "clf_linear = SVC(kernel='linear')\n",
        "clf_linear.fit(X_train, y_train)\n",
        "\n",
        "# Prédire sur l'ensemble de test\n",
        "y_pred = clf_linear.predict(X_test)\n",
        "\n",
        "# check your score\n",
        "print('Generalization score for linear kernel: %s, %s' %\n",
        "      (clf_linear.score(X_train, y_train),\n",
        "       clf_linear.score(X_test, y_test)))"
      ],
      "id": "d1c2cbeb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Le score sur les données d'entraînements est de 0.74 ce qui signifie que le modèle à classifié correctement 74% des exemples de l'ensemble de test ou de validation.\n",
        "Le score obtenu sur les données de test est de 0,66, ce qui correspond à un taux de classification correcte de 66 %. Cela indique que le modèle a moins bien réussi à classer les données de test par rapport aux données d'entraînement ou de validation.\n",
        "Nous pouvons donc nous dire que la classification linéaire est \"trop simple\" est qu'un autre noyau est peut être plus adapté à nos données. C'est ce que nous allons voir dans la question 2 avec un noyau polynomial.\n",
        "\n",
        "### Question 2 \n"
      ],
      "id": "682bfe2a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X = X[y != 0, :2]\n",
        "y = y[y != 0]\n",
        "X, y = shuffle(X, y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "Cs = list(np.logspace(-3, 3, 5))\n",
        "gammas = 10. ** np.arange(1, 2)\n",
        "degrees = np.r_[1, 2, 3]\n",
        "\n",
        "parameters = {'kernel': ['poly'], 'C': Cs, 'gamma': gammas, 'degree': degrees}\n",
        "\n",
        "clf_poly = SVC(kernel='poly')\n",
        "clf_poly.fit(X_train, y_train)\n",
        "\n",
        "# Prédire sur l'ensemble de test\n",
        "y_pred = clf_poly.predict(X_test)\n",
        "\n",
        "# check your score\n",
        "print('Generalization score for polynomial kernel: %s, %s' %\n",
        "      (clf_poly.score(X_train, y_train),\n",
        "       clf_poly.score(X_test, y_test)))"
      ],
      "id": "053f24f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous nous retrouvons maintenant avec un score de 0.7 avec un noyau polynomial pour les données d'entrainement et un score de 0.76 pour les données de tests. C'est mieux que pour le noyau linéaire pour les données de tests mais moins bon pour les données d'entraînement.\n",
        "\n",
        "### Visualisation de la classification \n"
      ],
      "id": "6b6d68cc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "def f_linear(xx):\n",
        "    \"\"\"Classifier: needed to avoid warning due to shape issues\"\"\"\n",
        "    return clf_linear.predict(xx.reshape(1, -1))\n",
        "\n",
        "def f_poly(xx):\n",
        "    \"\"\"Classifier: needed to avoid warning due to shape issues\"\"\"\n",
        "    return clf_poly.predict(xx.reshape(1, -1))\n",
        "\n",
        "plt.ion()\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.subplot(131)\n",
        "plot_2d(X, y)\n",
        "plt.title(\"iris dataset\")\n",
        "\n",
        "plt.subplot(132)\n",
        "frontiere(f_linear, X, y)\n",
        "plt.title(\"linear kernel\")\n",
        "\n",
        "plt.subplot(133)\n",
        "frontiere(f_poly, X, y)\n",
        "\n",
        "plt.title(\"polynomial kernel\")\n",
        "plt.tight_layout()\n",
        "plt.draw()"
      ],
      "id": "938f097b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Le graphique de gauche représente notre jeu de donnée 'Iris' et plus particulièrement, la variable \"sepal.width\" de Iris.\n",
        "\n",
        "- Le graphique du milieu corresponds à la classification du jeu de donnée par la méthode SVM avec un noyau linéaire. La ligne diagonale représente la frontière de séparation linéaire entre les deux classes. Les zones colorées en bleu et orange correspondent aux régions où le modèle prévoit chaque classe.On remarque que la frontière est une ligne droite, ce qui est caractéristique d'un noyau linéaire. Cependant, on observe également que plusieurs points de chaque classe se trouvent de l'autre côté de la frontière, ce qui indique que le noyau linéaire a du mal à séparer parfaitement les classes qui se chevauchent.\n",
        "\n",
        "- Le graphique de droite corresponds à la classification du jeu de donnée par la méthode SVM avec un noyau polynomial. On peut voir que la région en bleu et orange est moins simplement séparée, et le modèle semble mieux classer certains des points proches de la frontière par rapport au modèle linéaire.\n",
        "\n",
        "\\textbf{Conclusion :} Le noyau polynomial nous semble plus adapté aux différents jeu de données car il est plus complexe et permet une plus grande flexibilité pour la frontière car n'étant pas forcément linéaire. Cependant, dans notre cas, nous avons observé que la différence entre les deux scores n'était pas significative. Cela pourrait s'expliquer par la variable \"sepal.width\" du jeu de données Iris, qui permet une bonne séparation des deux classes à l'aide d'une simple ligne droite.\n",
        "\n",
        "## Classification des visages \n",
        "\n",
        "L'exemple suivant est un problème de classification de visages. Nous utilisons une base de donnée qui nous a été fournie et dans cette partie, nous nous concentrerons sur 2 personnes : 'Tony Blair' et 'Colin Powell'.\n",
        "\n",
        "### Question 4\n",
        "\n",
        "Nous avons ici 12 visages correspondant à ces 2 personnes.\n"
      ],
      "id": "c910be72"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "# Download the data and unzip; then load it as numpy arrays\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4,\n",
        "                              color=True, funneled=False, slice_=None,\n",
        "                              download_if_missing=True)\n",
        "# data_home='.'\n",
        "\n",
        "# introspect the images arrays to find the shapes (for plotting)\n",
        "images = lfw_people.images\n",
        "n_samples, h, w, n_colors = images.shape\n",
        "\n",
        "# the label to predict is the id of the person\n",
        "target_names = lfw_people.target_names.tolist()\n",
        "\n",
        "####################################################################\n",
        "# Pick a pair to classify such as\n",
        "names = ['Tony Blair', 'Colin Powell']\n",
        "#names = ['Donald Rumsfeld', 'Colin Powell']\n",
        "\n",
        "idx0 = (lfw_people.target == target_names.index(names[0]))\n",
        "idx1 = (lfw_people.target == target_names.index(names[1]))\n",
        "images = np.r_[images[idx0], images[idx1]]\n",
        "n_samples = images.shape[0]\n",
        "y = np.r_[np.zeros(np.sum(idx0)), np.ones(np.sum(idx1))].astype(int)\n",
        "\n",
        "# plot a sample set of the data\n",
        "plot_gallery(images, np.arange(12))\n",
        "plt.show()\n",
        "\n",
        "X = (np.mean(images, axis=3)).reshape(n_samples, -1)\n",
        "X -= np.mean(X, axis=0)\n",
        "X /= np.std(X, axis=0)"
      ],
      "id": "0e0bf851",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "def run_svm_cv(_X, _y):\n",
        "    _indices = np.random.permutation(_X.shape[0])\n",
        "    _train_idx, _test_idx = _indices[:_X.shape[0] // 2], _indices[_X.shape[0] // 2:]\n",
        "    _X_train, _X_test = _X[_train_idx, :], _X[_test_idx, :]\n",
        "    _y_train, _y_test = _y[_train_idx], _y[_test_idx]\n",
        "\n",
        "    _parameters = {'kernel': ['linear'], 'C': list(np.logspace(-5, 5, 11))}\n",
        "    _svr = svm.SVC()\n",
        "    _clf_linear = GridSearchCV(_svr, _parameters)\n",
        "    _clf_linear.fit(_X_train, _y_train)\n",
        "\n",
        "    print('Generalization score for linear kernel: %s, %s \\n' %\n",
        "          (_clf_linear.score(_X_train, _y_train), _clf_linear.score(_X_test, _y_test)))\n",
        "\n",
        "print(\"Score sans variable de nuisance\")\n",
        "run_svm_cv(X,y)"
      ],
      "id": "58fef588",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\textit{Rappels} : \n",
        "- Le score est le pourcentage de classification correcte. L'erreur est donc calculée en faisant 1-score.\n",
        "- Le paramètre C contrôle la complexité du classifieur dans la mesure où il détermine le coût d’une\n",
        "mauvaise classification : plus C est grand, plus la règle obtenue est complexe (le nombre de points pour\n",
        "lesquels on veut minimiser l’erreur de classification croît).\n",
        "\n",
        "\n",
        "Nous allons maintenant montrez l’influence de ce paramètre de régularisation C en le faisant varier sur une échelle logarithmique entre 1e5 et 1e-5.\n"
      ],
      "id": "c8b58132"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def run_svm_cv2(X, y):\n",
        "    _C_values = np.logspace(-5, 5, 11) \n",
        "    train_errors = []\n",
        "    test_errors = []\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "    for C in _C_values:\n",
        "        clf = svm.SVC(kernel='linear', C=C)\n",
        "        \n",
        "        clf.fit(X_train, y_train)\n",
        "        \n",
        "        train_score = clf.score(X_train, y_train)\n",
        "        test_score = clf.score(X_test, y_test)\n",
        "\n",
        "        train_errors.append(1 - train_score)\n",
        "        test_errors.append(1 - test_score)   \n",
        "\n",
        "    return _C_values, train_errors, test_errors\n",
        "\n",
        "C_values, train_errors, test_errors = run_svm_cv2(X, y)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogx(C_values, train_errors, label='Erreur d\\'entraînement', marker='o')\n",
        "plt.semilogx(C_values, test_errors, label='Erreur de test', marker='o')\n",
        "plt.xlabel('Paramètre de régularisation C')\n",
        "plt.ylabel('Erreur de prédiction')\n",
        "plt.title('Influence du paramètre de régularisation C sur l\\'erreur de prédiction')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "59e839e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quand la valeur de C est petite l'erreur sur les données d'entrainement et de test est grande (dee l'ordre de 0.4) et plus la valeur de C augmente, plus l'erreur diminue pour se stabilisé à 0.1 pour l'erreur sur les données de test à partir de C= 1e-3. Cette tendance est aussi vérifié pour l'erreur sur les données de tests, mais cette fois, l'erreur se stabilise autour de 0 à partir de C=1e-3.\n",
        "C'est ce que nous avons vu plus haut avec le score sans variable de nuissance où nous avions un score qui se stabilisait à 1 et un score sur les données d'entrainement d'environ 0.93.\n",
        "\n",
        "\n",
        "\n",
        "### Question 5 :\n",
        "Nous allons voir maintenant l'influence des variables de nuissance sur le score. \n"
      ],
      "id": "a624c4cd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "print(\"Score avec variable de nuisance\")\n",
        "n_features = X.shape[1]\n",
        "# On rajoute des variables de nuisances\n",
        "sigma = 1\n",
        "noise = sigma * np.random.randn(n_samples, 300, )\n",
        "X_noisy = np.concatenate((X, noise), axis=1)\n",
        "X_noisy = X_noisy[np.random.permutation(X.shape[0])]\n",
        "print(run_svm_cv(X_noisy,y))\n",
        "C_values, train_errors, test_errors = run_svm_cv2(X_noisy, y)\n",
        "\n",
        "# Tracer l'erreur de prédiction en fonction de C\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogx(C_values, train_errors, label='Erreur d\\'entraînement', marker='o')\n",
        "plt.semilogx(C_values, test_errors, label='Erreur de test', marker='o')\n",
        "plt.xlabel('Paramètre de régularisation C')\n",
        "plt.ylabel('Erreur de prédiction')\n",
        "plt.title('Influence des variables de nuisance sur l\\'erreur de prédiction')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "4e989976",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On remarque tout d'abord que le score a drastiquement diminué, il atteint 0.61 pour le score de test et 0.64 pour le score sur les données d'entraînement.\n",
        "\n",
        "Sur le graphique, nous nous rendons compte de l'influence du paramètre de régularisation, une nouvelle fois, l'erreur de précision sur les données d'entraînement se stabilise à 0 à partir de C=1e-3. Pour l'erreur sur les données de test par contre, il se stabiliuse autour de 0.45 à partir de C=1e-2. Cela suggère que le modèle est trop influencé par les variables de nuisance.\n",
        "\n",
        "### Question 6 :\n",
        "\n",
        "Nous allons maintenant essayer d'améliorer la prédiction à l'aide d'une réduction de dimension basé sur la PCA.\n"
      ],
      "id": "e27c1886"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "def run_svm_cv(X, y, n_components):\n",
        "    # Réduction de dimension avec PCA\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_reduced = pca.fit_transform(X)\n",
        "    \n",
        "    # Division des données\n",
        "    indices = np.random.permutation(X_reduced.shape[0])\n",
        "    train_idx, test_idx = indices[:X_reduced.shape[0] // 2], indices[X_reduced.shape[0] // 2:]\n",
        "    X_train, X_test = X_reduced[train_idx, :], X_reduced[test_idx, :]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "    \n",
        "    # Paramètres pour le SVM\n",
        "    parameters = {'kernel': ['linear'], 'C': list(np.logspace(-5, 5, 11))}\n",
        "    svr = svm.SVC()\n",
        "    clf = GridSearchCV(svr, parameters)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Scores\n",
        "    train_score = clf.score(X_train, y_train)\n",
        "    test_score = clf.score(X_test, y_test)\n",
        "\n",
        "    return train_score, test_score\n",
        "\n",
        "# Exemple d'utilisation\n",
        "n_components_list = [5, 10, 20, 50]\n",
        "train_errors = []\n",
        "test_errors = []\n",
        "\n",
        "# Charger vos données\n",
        "# Assurez-vous que X_noisy et y sont déjà définis\n",
        "for n_components in n_components_list:\n",
        "    train_score, test_score = run_svm_cv(X_noisy, y, n_components)\n",
        "    train_errors.append(1 - train_score)  # erreur = 1 - score\n",
        "    test_errors.append(1 - test_score)\n",
        "\n",
        "# Tracer les résultats\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(n_components_list, train_errors, marker='o', label=\"Erreur d'entraînement\")\n",
        "plt.plot(n_components_list, test_errors, marker='o', label=\"Erreur de test\")\n",
        "plt.xscale('linear')\n",
        "plt.xticks(n_components_list)\n",
        "plt.xlabel(\"Nombre de composants (n_components)\")\n",
        "plt.ylabel(\"Erreur de prédiction\")\n",
        "plt.title(\"Influence de la réduction de dimension sur l'erreur de prédiction\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "d11ca8a5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}